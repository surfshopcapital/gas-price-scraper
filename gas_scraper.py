import time
import schedule
from datetime import datetime, timezone
# import undetected_chromedriver as uc  # Commented out due to instability
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium import webdriver
import random
import psycopg2
import os
import pandas as pd

class GasScraper:
    def __init__(self, db_path="gas_prices.duckdb", headless=True):
        """Initialize the Gas Scraper with DuckDB"""
        self.db_path = db_path
        self.headless = headless
        self.driver = None
        
        # Initialize database
        self.init_database()
        
    def init_database(self):
        """Initialize PostgreSQL database connection (table creation handled by setup_database.py)"""
        try:
            # For Railway deployment, the table is already created by setup_database.py
            # Just verify we can connect to PostgreSQL
            database_url = os.getenv('DATABASE_URL', 'postgresql://postgres:QKmnqfjnamSWVXIgeEZZctczGSYOZiKw@switchback.proxy.rlwy.net:51447/railway')
            conn = psycopg2.connect(database_url)
            cursor = conn.cursor()
            
            # Simple test query to verify connection
            cursor.execute("SELECT COUNT(*) FROM gas_prices")
            count = cursor.fetchone()[0]
            print(f"âœ… Connected to PostgreSQL database. Found {count} existing records.")
            
            # Table already exists in PostgreSQL
            
            # PostgreSQL uses SERIAL for auto-incrementing
            
            # Add consensus and surprise columns if they don't exist (for existing tables)
            try:
                conn.execute("ALTER TABLE gas_prices ADD COLUMN consensus DOUBLE")
                print("   âœ… Added consensus column")
            except:
                pass  # Column already exists
                
            try:
                conn.execute("ALTER TABLE gas_prices ADD COLUMN surprise DOUBLE")
                print("   âœ… Added surprise column")
            except:
                pass  # Column already exists
            
            conn.close()
            print(f"âœ… Database initialized: {self.db_path}")
            
        except Exception as e:
            print(f"âŒ Error initializing database: {e}")
    
    def cleanup_chrome_processes(self):
        """Force cleanup of any lingering Chrome processes"""
        try:
            import subprocess
            import os
            
            # Kill any existing Chrome processes on Windows
            if os.name == 'nt':  # Windows
                try:
                    subprocess.run(['taskkill', '/f', '/im', 'chrome.exe'], 
                                 capture_output=True, check=False)
                    subprocess.run(['taskkill', '/f', '/im', 'chromedriver.exe'], 
                                 capture_output=True, check=False)
                    time.sleep(1)  # Wait for processes to be killed
                    print("   ğŸ§¹ Cleaned up Chrome processes")
                except:
                    pass
        except Exception as e:
            print(f"   âš ï¸ Chrome cleanup warning: {e}")
    
    def setup_chrome_driver(self):
        """Set up Chrome driver with CDP capabilities"""
        try:
            print("ğŸ”§ Setting up Chrome driver...")
            
            # Force cleanup of any existing driver
            if hasattr(self, 'driver') and self.driver:
                try:
                    self.driver.quit()
                except:
                    pass
                self.driver = None
            
            # Force cleanup of Chrome processes
            self.cleanup_chrome_processes()
            
            options = Options()
            
            if self.headless:
                print("   ğŸ‘» Running in headless mode")
                options.add_argument('--headless')
            else:
                print("   ğŸ“± Running in visible mode")
            
            # Anti-detection options
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-gpu')
            options.add_argument('--disable-plugins')
            options.add_argument('--disable-images')
            # options.add_argument('--disable-javascript')  # Commented out - needed for dynamic content
            
            # User agent to look more human
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            print("   ğŸš€ Launching Chrome...")
            
            # Find Chrome binary and set up ChromeDriver for Railway environment
            try:
                print("   ğŸ” Looking for Chrome binary...")
                
                # Debug: Check what's actually in the system
                print("   ğŸ” Debugging system paths...")
                
                # Check PATH and common directories
                try:
                    result = subprocess.run(['echo', '$PATH'], capture_output=True, text=True, shell=True)
                    print(f"   ğŸ“ PATH: {result.stdout.strip()}")
                except:
                    print("   ğŸ“ Could not check PATH")
                
                # Check what's in /usr/bin
                try:
                    result = subprocess.run(['ls', '-la', '/usr/bin/'], capture_output=True, text=True)
                    chrome_files = [line for line in result.stdout.split('\n') if 'chrome' in line.lower() or 'chromium' in line.lower()]
                    if chrome_files:
                        print(f"   ğŸ“ Chrome files in /usr/bin: {chrome_files}")
                    else:
                        print("   ğŸ“ No Chrome files found in /usr/bin")
                except:
                    print("   ğŸ“ Could not check /usr/bin")
                
                # Check nix store for chromium
                try:
                    result = subprocess.run(['find', '/nix/store', '-name', 'chromium', '-type', 'f'], capture_output=True, text=True)
                    if result.stdout.strip():
                        chromium_paths = result.stdout.strip().split('\n')
                        print(f"   ğŸ“ Found chromium in nix store: {chromium_paths}")
                    else:
                        print("   ğŸ“ No chromium found in nix store")
                except:
                    print("   ğŸ“ Could not search nix store")
                
                # Check nix store for chromedriver
                try:
                    result = subprocess.run(['find', '/nix/store', '-name', 'chromedriver', '-type', 'f'], capture_output=True, text=True)
                    if result.stdout.strip():
                        chromedriver_paths = result.stdout.strip().split('\n')
                        print(f"   ğŸ“ Found chromedriver in nix store: {chromedriver_paths}")
                    else:
                        print("   ğŸ“ No chromedriver found in nix store")
                except:
                    print("   ğŸ“ Could not search nix store")
                
                # Common Chrome/Chromium paths in Railway/nixpacks environment
                chrome_paths = [
                    "/nix/store/*/chromium/bin/chromium",
                    "/usr/bin/chromium",
                    "/usr/bin/chromium-browser",
                    "/usr/bin/google-chrome",
                    "/usr/bin/google-chrome-stable"
                ]
                
                # Try to find an available Chrome binary
                import subprocess
                import glob
                chrome_found = False
                
                for chrome_path in chrome_paths:
                    if '*' in chrome_path:
                        # Handle wildcard paths (nixpacks)
                        expanded_paths = glob.glob(chrome_path)
                        print(f"   ğŸ” Expanded path '{chrome_path}' to: {expanded_paths}")
                        for expanded_path in expanded_paths:
                            if subprocess.run(['test', '-f', expanded_path], capture_output=True).returncode == 0:
                                options.binary_location = expanded_path
                                print(f"   ğŸ” Found Chrome at: {expanded_path}")
                                chrome_found = True
                                break
                        if chrome_found:
                            break
                    else:
                        # Handle direct paths
                        if subprocess.run(['test', '-f', chrome_path], capture_output=True).returncode == 0:
                            options.binary_location = chrome_path
                            print(f"   ğŸ” Found Chrome at: {chrome_path}")
                            chrome_found = True
                            break
                
                if not chrome_found:
                    print("   âŒ Chrome binary not found in any expected location")
                    return None
                
                # Create Chrome driver with found binary
                self.driver = webdriver.Chrome(options=options)
                print("   âœ… Chrome driver created successfully")
            except Exception as e:
                print(f"   âŒ ChromeDriver setup failed: {e}")
                return None
            
            # Set window size
            self.driver.set_window_size(1920, 1080)
            print("   âœ… Chrome driver setup complete")
            
            return self.driver
            
        except Exception as e:
            print(f"âŒ Error setting up Chrome driver: {e}")
            return None
    
    def scrape_gasbuddy(self):
        """Scrape GasBuddy Fuel Insights"""
        try:
            print("ğŸš€ Starting GasBuddy scraping...")
            
            # Setup Chrome driver
            if not self.setup_chrome_driver():
                print("âŒ Failed to setup Chrome driver")
                return None
            
            # Set location permissions and coordinates BEFORE navigating
            print("ğŸ“ Setting geolocation permissions and coordinates...")
            
            # US cities with coordinates for randomization
            us_cities = [
                {"name": "New York", "lat": 40.7128, "lng": -74.0060},
                {"name": "Los Angeles", "lat": 34.0522, "lng": -118.2437},
                {"name": "Chicago", "lat": 41.8781, "lng": -87.6298},
                {"name": "Houston", "lat": 29.7604, "lng": -95.3698},
                {"name": "Phoenix", "lat": 33.4484, "lng": -112.0740}
            ]
            
            # Randomly select a US city
            selected_city = random.choice(us_cities)
            print(f"   ğŸ™ï¸ Selected location: {selected_city['name']}")
            
            # Grant geolocation permissions to the target domain FIRST
            try:
                self.driver.execute_cdp_cmd(
                    "Browser.grantPermissions",
                    {
                        "origin": "https://fuelinsights.gasbuddy.com/",
                        "permissions": ["geolocation"],
                    }
                )
                print("   âœ… Geolocation permissions granted")
            except Exception as e:
                print(f"   âš ï¸ Could not grant permissions: {e}")
            
            # Set the geolocation coordinates
            try:
                self.driver.execute_cdp_cmd(
                    "Emulation.setGeolocationOverride",
                    {
                        "latitude": selected_city['lat'],
                        "longitude": selected_city['lng'],
                        "accuracy": 100,
                    }
                )
                print("   âœ… Geolocation coordinates set")
            except Exception as e:
                print(f"   âš ï¸ Could not set coordinates: {e}")
            
            # Small delay to ensure CDP commands are processed
            time.sleep(1)
            
            # Navigate to GasBuddy AFTER setting permissions
            target_url = "https://fuelinsights.gasbuddy.com/"
            print(f"ğŸŒ Navigating to: {target_url}")
            self.driver.get(target_url)
            
            # Wait for SPA to load - longer wait since it's an SPA
            print("â³ Waiting for SPA to load...")
            time.sleep(8)
            
            # Try to wait for specific elements to appear
            try:
                from selenium.webdriver.support.ui import WebDriverWait
                from selenium.webdriver.support import expected_conditions as EC
                
                # Wait for the application host to have content
                WebDriverWait(self.driver, 15).until(
                    lambda driver: len(driver.find_element(By.ID, "applicationHost").text) > 100
                )
                print("   âœ… SPA content loaded")
            except Exception as e:
                print(f"   âš ï¸ SPA content may not be fully loaded: {e}")
            
            # Extract gas price data
            gas_data = self.extract_gasbuddy_data()
            
            if gas_data:
                print("ğŸ‰ Successfully extracted GasBuddy data!")
                return gas_data
            else:
                print("âŒ Failed to extract GasBuddy data")
                # Try to get page source for debugging
                try:
                    page_source = self.driver.page_source
                    if "tickingAvgPriceText" in page_source:
                        print("   ğŸ” Price element ID found in page source")
                    else:
                        print("   âŒ Price element ID not found in page source")
                        print(f"   ğŸ“„ Page title: {self.driver.title}")
                        print(f"   ğŸ”— Current URL: {self.driver.current_url}")
                except Exception as e:
                    print(f"   âš ï¸ Could not analyze page: {e}")
                return None
                
        except Exception as e:
            print(f"âŒ Error in GasBuddy scraping: {e}")
            return None
            
        finally:
            # Always close the driver
            if self.driver:
                print("ğŸ”’ Closing Chrome driver...")
                try:
                    self.driver.quit()
                except Exception as e:
                    print(f"âš ï¸ Warning during driver cleanup: {e}")
                self.driver = None
    
    def scrape_aaa(self):
        """Scrape AAA Gas Prices"""
        try:
            print("ğŸš— Starting AAA scraping...")
            
            # Setup Chrome driver
            if not self.setup_chrome_driver():
                print("âŒ Failed to setup Chrome driver")
                return None
            
            # Navigate to AAA
            target_url = "https://gasprices.aaa.com/"
            print(f"ğŸŒ Navigating to: {target_url}")
            self.driver.get(target_url)
            
            # Wait for page to load - longer wait for table data
            print("â³ Waiting for page to load...")
            time.sleep(8)
            
            # Try to wait for the table to appear
            try:
                from selenium.webdriver.support.ui import WebDriverWait
                from selenium.webdriver.support import expected_conditions as EC
                
                # Wait for the tbody element to have content
                WebDriverWait(self.driver, 15).until(
                    lambda driver: len(driver.find_element(By.TAG_NAME, "tbody").text) > 50
                )
                print("   âœ… AAA table data loaded")
            except Exception as e:
                print(f"   âš ï¸ AAA table may not be fully loaded: {e}")
            
            # Extract AAA data BEFORE any cleanup
            aaa_data = self.extract_aaa_data()
            
            if aaa_data:
                print("ğŸ‰ Successfully extracted AAA data!")
                return aaa_data
            else:
                print("âŒ Failed to extract AAA data")
                # Try to get page source for debugging
                try:
                    page_source = self.driver.page_source
                    if "Current Avg." in page_source:
                        print("   ğŸ” Current Avg. text found in page source")
                    else:
                        print("   âŒ Current Avg. text not found in page source")
                        print(f"   ğŸ“„ Page title: {self.driver.title}")
                        print(f"   ğŸ”— Current URL: {self.driver.current_url}")
                except Exception as e:
                    print(f"   âš ï¸ Could not analyze page: {e}")
                return None
                
        except Exception as e:
            print(f"âŒ Error in AAA scraping: {e}")
            return None
            
        finally:
            # Clean up driver AFTER data extraction
            if self.driver:
                print("ğŸ”’ Closing Chrome driver...")
                try:
                    self.driver.quit()
                except Exception as e:
                    print(f"âš ï¸ Warning during driver cleanup: {e}")
                self.driver = None
            
            # Force cleanup of Chrome processes
            self.cleanup_chrome_processes()
    
    def set_location_permissions_and_coordinates(self):
        """Set geolocation permissions and coordinates using CDP"""
        try:
            print("ğŸ“ Setting geolocation permissions and coordinates...")
            
            # US cities with coordinates for randomization
            us_cities = [
                {"name": "New York", "lat": 40.7128, "lng": -74.0060},
                {"name": "Los Angeles", "lat": 34.0522, "lng": -118.2437},
                {"name": "Chicago", "lat": 41.8781, "lng": -87.6298},
                {"name": "Houston", "lat": 29.7604, "lng": -95.3698},
                {"name": "Phoenix", "lat": 33.4484, "lng": -112.0740}
            ]
            
            # Randomly select a US city
            selected_city = random.choice(us_cities)
            print(f"   ğŸ™ï¸ Selected location: {selected_city['name']}")
            
            # Grant geolocation permissions to the target domain
            self.driver.execute_cdp_cmd(
                "Browser.grantPermissions",
                {
                    "origin": "https://fuelinsights.gasbuddy.com/",
                    "permissions": ["geolocation"],
                }
            )
            
            # Set the geolocation coordinates
            self.driver.execute_cdp_cmd(
                "Emulation.setGeolocationOverride",
                {
                    "latitude": selected_city['lat'],
                    "longitude": selected_city['lng'],
                    "accuracy": 100,
                }
            )
            
            print("   âœ… Location permissions and coordinates set")
            return selected_city
            
        except Exception as e:
            print(f"âŒ Error setting location permissions: {e}")
            return None
    
    def wait_for_spa_load(self):
        """Wait for the SPA to fully load and render"""
        try:
            print("â³ Waiting for SPA to load...")
            
            # Wait for the page to be ready
            WebDriverWait(self.driver, 10).until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
            
            # Wait for SPA content to start loading
            time.sleep(5)
            
            # Check if applicationHost has content
            app_host = self.driver.find_element(By.ID, "applicationHost")
            app_content = app_host.text.strip()
            
            if len(app_content) > 1000:
                print("   âœ… SPA content loaded successfully")
                return True
            else:
                print("   âš ï¸ SPA content still minimal, waiting longer...")
                time.sleep(10)
                
                # Check again
                app_content = app_host.text.strip()
                if len(app_content) > 1000:
                    print("   âœ… SPA content loaded after additional wait")
                    return True
                else:
                    print("   âŒ SPA content failed to load")
                    return False
                    
        except Exception as e:
            print(f"âŒ Error waiting for SPA load: {e}")
            return False
    
    def extract_gasbuddy_data(self):
        """Extract gas price data from GasBuddy"""
        try:
            print("ğŸ” Extracting GasBuddy data...")
            
            # Look for the gas price element
            price_element = self.driver.find_element(By.ID, "tickingAvgPriceText")
            price_text = price_element.text.strip()
            print(f"   âœ… Found gas price: {price_text}")
            
            # Look for timestamp
            timestamp = "Unknown"
            try:
                timestamp_element = self.driver.find_element(By.CSS_SELECTOR, "div[data-bind*='tickingAvgLastUpdated']")
                timestamp = timestamp_element.text.strip()
                print(f"   ğŸ•’ Found timestamp: {timestamp}")
            except NoSuchElementException:
                print("   âš ï¸ Timestamp element not found")
            
            # Extract price
            try:
                price = float(price_text)
                print(f"   ğŸ¯ Successfully extracted price: ${price}")
                return {
                    'price': price,
                    'timestamp': timestamp,
                    'region': 'United States',
                    'source': 'gasbuddy_fuel_insights',
                    'fuel_type': 'regular'
                }
                
            except ValueError:
                print(f"   âŒ Could not convert '{price_text}' to float")
                return None
                
        except NoSuchElementException:
            print("   âŒ Gas price element not found")
            return None
        except Exception as e:
            print(f"âŒ Error extracting GasBuddy data: {e}")
            return None
    
    def extract_gasbuddy_data_from_driver(self, driver):
        """Extract gas price data from GasBuddy using provided driver"""
        try:
            print("ğŸ” Extracting GasBuddy data...")
            
            # Look for the gas price element
            price_element = driver.find_element(By.ID, "tickingAvgPriceText")
            price_text = price_element.text.strip()
            print(f"   âœ… Found gas price: {price_text}")
            
            # Look for timestamp
            timestamp = "Unknown"
            try:
                timestamp_element = driver.find_element(By.CSS_SELECTOR, "div[data-bind*='tickingAvgLastUpdated']")
                timestamp = timestamp_element.text.strip()
                print(f"   ğŸ•’ Found timestamp: {timestamp}")
            except NoSuchElementException:
                print("   âš ï¸ Timestamp element not found")
            
            # Extract price
            try:
                # Remove '$' and convert to float
                price = float(price_text.replace('$', ''))
                print(f"   ğŸ¯ Successfully extracted gas price: ${price}")
                
                return {
                    'price': price,
                    'timestamp': timestamp,
                    'region': 'United States',
                    'source': 'gasbuddy_fuel_insights',
                    'fuel_type': 'regular_gas'
                }
                
            except ValueError:
                print(f"   âŒ Could not convert price '{price_text}' to float")
                return None
                
        except Exception as e:
            print(f"âŒ Error extracting GasBuddy data: {e}")
            return None
    
    def extract_aaa_data(self):
        """Extract gas price data from AAA"""
        try:
            print("ğŸ” Extracting AAA data...")
            
            # Find the table with the price data
            table = self.driver.find_element(By.TAG_NAME, "tbody")
            rows = table.find_elements(By.TAG_NAME, "tr")
            
            current_price = None
            
            # Extract data from each row - only look for Current Avg.
            for row in rows:
                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) >= 2:
                    period = cells[0].text.strip()
                    regular_price = cells[1].text.strip()
                    
                    if "Current Avg." in period:
                        current_price = regular_price.replace('$', '').strip()
                        print(f"   âœ… Current Avg.: ${current_price}")
                        break  # Only get the first Current Avg. row
            
            if current_price:
                # Save only the current price
                try:
                    current_float = float(current_price)
                    result = {
                        'price': current_float,
                        'timestamp': f"Current as of {datetime.now().strftime('%Y-%m-%d')}",
                        'region': 'United States',
                        'source': 'aaa_gas_prices',
                        'fuel_type': 'regular'
                    }
                    print(f"   ğŸ¯ Current price: ${current_float}")
                    return result
                except ValueError:
                    print(f"   âŒ Could not convert current price '{current_price}' to float")
                    return None
            else:
                print("   âŒ Could not find current price")
                return None
                
        except Exception as e:
            print(f"âŒ Error extracting AAA data: {e}")
            return None
    
    def extract_aaa_data_from_driver(self, driver):
        """Extract gas price data from AAA using provided driver"""
        try:
            print("ğŸ” Extracting AAA data...")
            
            # Find the table with the price data
            table = driver.find_element(By.TAG_NAME, "tbody")
            rows = table.find_elements(By.TAG_NAME, "tr")
            
            current_price = None
            
            # Extract data from each row - only look for Current Avg.
            for row in rows:
                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) >= 2:
                    period = cells[0].text.strip()
                    regular_price = cells[1].text.strip()
                    
                    if "Current Avg." in period:
                        current_price = regular_price.replace('$', '').strip()
                        print(f"   âœ… Current Avg.: ${current_price}")
                        break  # Only get the first Current Avg. row
            
            if current_price:
                # Save only the current price
                try:
                    current_float = float(current_price)
                    result = {
                        'price': current_float,
                        'timestamp': f"Current as of {datetime.now().strftime('%Y-%m-%d')}",
                        'region': 'United States',
                        'source': 'aaa_gas_prices',
                        'fuel_type': 'regular'
                    }
                    print(f"   ğŸ¯ Current price: ${current_float}")
                    return result
                except ValueError:
                    print(f"   âŒ Could not convert current price '{current_price}' to float")
                    return None
            else:
                print("   âŒ Could not find current price")
                return None
                
        except Exception as e:
            print(f"âŒ Error extracting AAA data: {e}")
            return None
    
    def scrape_rbob(self):
        """Scrape RBOB Futures from MarketWatch"""
        driver = None
        try:
            print("â›½ Starting RBOB futures scraping...")
            
            # Setup Chrome driver
            if not self.setup_chrome_driver():
                print("âŒ Failed to setup Chrome driver")
                return None
            
            # Store reference to driver
            driver = self.driver
            
            # Navigate to MarketWatch RBOB futures
            target_url = "https://www.marketwatch.com/investing/future/rb.1"
            print(f"ğŸŒ Navigating to: {target_url}")
            driver.get(target_url)
            
            # Wait for page to load
            print("â³ Waiting for page to load...")
            time.sleep(5)
            
            # Extract RBOB data BEFORE any cleanup
            rbob_data = self.extract_rbob_data()
            
            if rbob_data:
                print("ğŸ‰ Successfully extracted RBOB data!")
                return rbob_data
            else:
                print("âŒ Failed to extract RBOB data")
                return None
                
        except Exception as e:
            print(f"âŒ Error in RBOB scraping: {e}")
            return None
            
        finally:
            # Clean up driver AFTER data extraction
            if driver:
                print("ğŸ”’ Closing Chrome driver...")
                try:
                    driver.quit()
                except Exception as e:
                    print(f"âš ï¸ Warning during driver cleanup: {e}")
                self.driver = None
            
            # Force cleanup of Chrome processes
            self.cleanup_chrome_processes()
    
    def extract_rbob_data(self):
        """Extract RBOB futures data from MarketWatch"""
        try:
            print("ğŸ” Extracting RBOB futures data...")
            
            # Find the price element
            price_element = self.driver.find_element(By.CSS_SELECTOR, "span.value")
            price_text = price_element.text.strip()
            print(f"   âœ… Found RBOB price: ${price_text}")
            
            # Find the timestamp element
            timestamp_element = self.driver.find_element(By.CSS_SELECTOR, "span.timestamp__time")
            timestamp_text = timestamp_element.text.strip()
            print(f"   ğŸ•’ Found timestamp: {timestamp_text}")
            
            # Extract price
            try:
                price = float(price_text)
                print(f"   ğŸ¯ Successfully extracted RBOB price: ${price}")
                
                # Clean up timestamp text
                timestamp = timestamp_text.replace("Last Updated: ", "").strip()
                
                return {
                    'price': price,
                    'timestamp': timestamp,
                    'region': 'United States',
                    'source': 'marketwatch_rbob_futures',
                    'fuel_type': 'rbob_futures'
                }
                
            except ValueError:
                print(f"   âŒ Could not convert RBOB price '{price_text}' to float")
                return None
                
        except Exception as e:
            print(f"âŒ Error extracting RBOB data: {e}")
            return None
    
    def scrape_wti(self):
        """Scrape WTI Crude Oil Futures from MarketWatch"""
        driver = None
        try:
            print("ğŸ›¢ï¸ Starting WTI crude oil futures scraping...")
            
            # Setup Chrome driver
            if not self.setup_chrome_driver():
                print("âŒ Failed to setup Chrome driver")
                return None
            
            # Store reference to driver
            driver = self.driver
            
            # Navigate to MarketWatch WTI futures
            target_url = "https://www.marketwatch.com/investing/future/cl.1"
            print(f"ğŸŒ Navigating to: {target_url}")
            driver.get(target_url)
            
            # Wait for page to load
            print("â³ Waiting for page to load...")
            time.sleep(5)
            
            # Extract WTI data BEFORE any cleanup
            wti_data = self.extract_wti_data()
            
            if wti_data:
                print("ğŸ‰ Successfully extracted WTI data!")
                return wti_data
            else:
                print("âŒ Failed to extract WTI data")
                return None
                
        except Exception as e:
            print(f"âŒ Error in WTI scraping: {e}")
            return None
            
        finally:
            # Clean up driver AFTER data extraction
            if driver:
                print("ğŸ”’ Closing Chrome driver...")
                try:
                    driver.quit()
                except Exception as e:
                    print(f"âš ï¸ Warning during driver cleanup: {e}")
                self.driver = None
    
    def extract_wti_data(self):
        """Extract WTI crude oil futures data from MarketWatch"""
        try:
            print("ğŸ” Extracting WTI crude oil futures data...")
            
            # Find the price element
            price_element = self.driver.find_element(By.CSS_SELECTOR, "span.value")
            price_text = price_element.text.strip()
            print(f"   âœ… Found WTI price: ${price_text}")
            
            # Find the timestamp element
            timestamp_element = self.driver.find_element(By.CSS_SELECTOR, "span.timestamp__time")
            timestamp_text = timestamp_element.text.strip()
            print(f"   ğŸ•’ Found timestamp: {timestamp_text}")
            
            # Extract price
            try:
                price = float(price_text)
                print(f"   ğŸ¯ Successfully extracted WTI price: ${price}")
                
                # Clean up timestamp text
                timestamp = timestamp_text.replace("Last Updated: ", "").strip()
                
                return {
                    'price': price,
                    'timestamp': timestamp,
                    'region': 'United States',
                    'source': 'marketwatch_wti_futures',
                    'fuel_type': 'wti_futures'
                }
                
            except ValueError:
                print(f"   âŒ Could not convert WTI price '{price_text}' to float")
                return None
                
        except Exception as e:
            print(f"âŒ Error extracting WTI data: {e}")
            return None
    
    def scrape_gasoline_stocks(self):
        """Scrape Gasoline Stocks Change from Trading Economics"""
        driver = None
        try:
            print("â›½ Starting Gasoline Stocks Change scraping...")
            
            # Setup Chrome driver
            if not self.setup_chrome_driver():
                print("âŒ Failed to setup Chrome driver")
                return None
            
            # Store reference to driver
            driver = self.driver
            
            # Navigate to Trading Economics Gasoline Stocks Change
            target_url = "https://tradingeconomics.com/united-states/gasoline-stocks-change"
            print(f"ğŸŒ Navigating to: {target_url}")
            driver.get(target_url)
            
            # Wait for page to load
            print("â³ Waiting for page to load...")
            time.sleep(8)
            
            # Extract Gasoline Stocks data BEFORE any cleanup
            stocks_data = self.extract_gasoline_stocks_data()
            
            if stocks_data:
                print("ğŸ‰ Successfully extracted Gasoline Stocks data!")
                return stocks_data
            else:
                print("âŒ Failed to extract Gasoline Stocks data")
                return None
                
        except Exception as e:
            print(f"âŒ Error in Gasoline Stocks scraping: {e}")
            return None
            
        finally:
            # Clean up driver AFTER data extraction
            if driver:
                print("ğŸ”’ Closing Chrome driver...")
                try:
                    driver.quit()
                except Exception as e:
                    print(f"âš ï¸ Warning during driver cleanup: {e}")
                self.driver = None
    
    def extract_gasoline_stocks_data(self):
        """Extract Gasoline Stocks Change data from Trading Economics"""
        try:
            print("ğŸ” Extracting Gasoline Stocks Change data...")
            
            # Find all rows with actual data
            actual_elements = self.driver.find_elements(By.CSS_SELECTOR, "td#actual")
            
            if not actual_elements:
                print("   âŒ No actual data elements found")
                return None
            
            # Find the most recent date with actual data
            latest_date = None
            latest_row = None
            latest_actual = None
            latest_consensus = None
            
            for actual_element in actual_elements:
                row = actual_element.find_element(By.XPATH, "./..")  # Go to parent tr
                date_element = row.find_element(By.XPATH, "./td[1]")
                date_text = date_element.text.strip()
                
                # Skip if no actual value
                actual_text = actual_element.text.strip()
                if not actual_text or actual_text == '':
                    continue
                
                # Parse date (format: YYYY-MM-DD)
                try:
                    date_parts = date_text.split('-')
                    if len(date_parts) == 3:
                        year, month, day = int(date_parts[0]), int(date_parts[1]), int(date_parts[2])
                        current_date = datetime(year, month, day).date()
                        
                        if latest_date is None or current_date > latest_date:
                            latest_date = current_date
                            latest_row = row
                            latest_actual = actual_text
                            
                            # Get consensus from the same row (7th column)
                            consensus_element = row.find_element(By.XPATH, "./td[7]")
                            latest_consensus = consensus_element.text.strip()
                            
                except (ValueError, IndexError) as e:
                    print(f"   âš ï¸ Could not parse date '{date_text}': {e}")
                    continue
            
            if latest_date is None:
                print("   âŒ No valid dates with actual data found")
                return None
            
            print(f"   ğŸ“… Found latest date: {latest_date}")
            print(f"   âœ… Found actual value: {latest_actual}")
            print(f"   ğŸ“Š Found consensus: {latest_consensus}")
            
            # Extract numeric values
            try:
                # Remove 'M' suffix and convert to float
                actual_value = float(latest_actual.replace('M', ''))
                consensus_value = float(latest_consensus.replace('M', '')) if latest_consensus and latest_consensus != '' else 0.0
                
                # Calculate surprise
                surprise = actual_value - consensus_value
                
                print(f"   ğŸ¯ Actual: {actual_value}M")
                print(f"   ğŸ¯ Consensus: {consensus_value}M")
                print(f"   ğŸ¯ Surprise: {surprise}M")
                
                return {
                    'price': actual_value,
                    'timestamp': f"{latest_date.strftime('%Y-%m-%d')}",
                    'region': 'United States',
                    'source': 'tradingeconomics_gasoline_stocks',
                    'fuel_type': 'gasoline_stocks_change',
                    'consensus': consensus_value,
                    'surprise': surprise
                }
                
            except ValueError as e:
                print(f"   âŒ Could not convert values to float: {e}")
                return None
                
        except Exception as e:
            print(f"âŒ Error extracting Gasoline Stocks data: {e}")
            return None
    
    def scrape_refinery_runs(self):
        """Scrape Refinery Crude Runs from Trading Economics"""
        driver = None
        try:
            print("ğŸ­ Starting Refinery Crude Runs scraping...")
            
            # Setup Chrome driver
            if not self.setup_chrome_driver():
                print("âŒ Failed to setup Chrome driver")
                return None
            
            # Store reference to driver
            driver = self.driver
            
            # Navigate to Trading Economics Refinery Crude Runs
            target_url = "https://tradingeconomics.com/united-states/refinery-crude-runs"
            print(f"ğŸŒ Navigating to: {target_url}")
            driver.get(target_url)
            
            # Wait for page to load
            print("â³ Waiting for page to load...")
            time.sleep(8)
            
            # Extract Refinery Runs data BEFORE any cleanup
            runs_data = self.extract_refinery_runs_data()
            
            if runs_data:
                print("ğŸ‰ Successfully extracted Refinery Crude Runs data!")
                return runs_data
            else:
                print("âŒ Failed to extract Refinery Crude Runs data")
                return None
                
        except Exception as e:
            print(f"âŒ Error in Refinery Runs scraping: {e}")
            return None
            
        finally:
            # Clean up driver AFTER data extraction
            if driver:
                print("ğŸ”’ Closing Chrome driver...")
                try:
                    driver.quit()
                except Exception as e:
                    print(f"âš ï¸ Warning during driver cleanup: {e}")
                self.driver = None
    
    def extract_refinery_runs_data(self):
        """Extract Refinery Crude Runs data from Trading Economics"""
        try:
            print("ğŸ” Extracting Refinery Crude Runs data...")
            
            # Find all rows with actual data
            actual_elements = self.driver.find_elements(By.CSS_SELECTOR, "td#actual")
            
            if not actual_elements:
                print("   âŒ No actual data elements found")
                return None
            
            # Find the most recent date with actual data
            latest_date = None
            latest_actual = None
            
            for actual_element in actual_elements:
                row = actual_element.find_element(By.XPATH, "./..")  # Go to parent tr
                date_element = row.find_element(By.XPATH, "./td[1]")
                date_text = date_element.text.strip()
                
                # Skip if no actual value
                actual_text = actual_element.text.strip()
                if not actual_text or actual_text == '':
                    continue
                
                # Parse date (format: YYYY-MM-DD)
                try:
                    date_parts = date_text.split('-')
                    if len(date_parts) == 3:
                        year, month, day = int(date_parts[0]), int(date_parts[1]), int(date_parts[2])
                        current_date = datetime(year, month, day).date()
                        
                        if latest_date is None or current_date > latest_date:
                            latest_date = current_date
                            latest_actual = actual_text
                            
                except (ValueError, IndexError) as e:
                    print(f"   âš ï¸ Could not parse date '{date_text}': {e}")
                    continue
            
            if latest_date is None:
                print("   âŒ No valid dates with actual data found")
                return None
            
            print(f"   ğŸ“… Found latest date: {latest_date}")
            print(f"   âœ… Found actual value: {latest_actual}")
            
            # Extract numeric value
            try:
                # Remove 'M' suffix and convert to float
                actual_value = float(latest_actual.replace('M', ''))
                
                print(f"   ğŸ¯ Actual: {actual_value}M")
                
                return {
                    'price': actual_value,
                    'timestamp': f"{latest_date.strftime('%Y-%m-%d')}",
                    'region': 'United States',
                    'source': 'tradingeconomics_refinery_runs',
                    'fuel_type': 'refinery_crude_runs'
                }
                
            except ValueError as e:
                print(f"   âŒ Could not convert value to float: {e}")
                return None
                
        except Exception as e:
            print(f"âŒ Error extracting Refinery Runs data: {e}")
            return None
    
    def save_to_database(self, gas_data_list):
        """Save gas price data to PostgreSQL"""
        if not gas_data_list:
            return False
        
        # Handle single item or list
        if not isinstance(gas_data_list, list):
            gas_data_list = [gas_data_list]
            
        try:
            # Get database connection from environment variables
            database_url = os.getenv('DATABASE_URL', 'postgresql://postgres:QKmnqfjnamSWVXIgeEZZctczGSYOZiKw@switchback.proxy.rlwy.net:51447/railway')
            conn = psycopg2.connect(database_url)
            cursor = conn.cursor()
            
            saved_count = 0
            for gas_data in gas_data_list:
                # Check if consensus and surprise exist (for EIA data)
                consensus = gas_data.get('consensus', None)
                surprise = gas_data.get('surprise', None)
                
                # Insert the data with auto-incrementing ID (PostgreSQL uses SERIAL)
                cursor.execute('''
                    INSERT INTO gas_prices (price, timestamp, region, source, fuel_type, consensus, surprise, scraped_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
                ''', (gas_data['price'], gas_data['timestamp'], gas_data['region'], gas_data['source'], gas_data['fuel_type'], consensus, surprise))
                
                saved_count += 1
                print(f"   âœ… Saved: ${gas_data['price']} from {gas_data['source']}")
                if consensus is not None and surprise is not None:
                    print(f"      ğŸ“Š Consensus: {consensus}M, Surprise: {surprise}M")
            
            conn.commit()
            cursor.close()
            conn.close()
            
            print(f"âœ… Successfully saved {saved_count} records to database")
            return True
            
        except Exception as e:
            print(f"âŒ Error saving to database: {e}")
            return False
    
    def run_gasbuddy_job(self):
        """Run GasBuddy scraping job"""
        print(f"\n--- Starting GasBuddy scraping job at {datetime.now()} ---")
        
        gas_data = self.scrape_gasbuddy()
        if gas_data:
            self.save_to_database(gas_data)
            print(f"ğŸ¯ GasBuddy: ${gas_data['price']} at {gas_data['timestamp']}")
        else:
            print("âŒ Failed to scrape GasBuddy data")
    
    def run_aaa_job(self):
        """Run AAA scraping job"""
        print(f"\n--- Starting AAA scraping job at {datetime.now()} ---")
        
        aaa_data = self.scrape_aaa()
        if aaa_data:
            self.save_to_database(aaa_data)
            print(f"ğŸ¯ AAA: Extracted current price: ${aaa_data['price']}")
        else:
            print("âŒ Failed to scrape AAA data")
    
    def run_rbob_job(self):
        """Run RBOB futures scraping job"""
        print(f"\n--- Starting RBOB futures scraping job at {datetime.now()} ---")
        
        rbob_data = self.scrape_rbob()
        if rbob_data:
            self.save_to_database(rbob_data)
            print(f"ğŸ¯ RBOB: ${rbob_data['price']} at {rbob_data['timestamp']}")
        else:
            print("âŒ Failed to scrape RBOB data")
    
    def run_wti_job(self):
        """Run WTI crude oil futures scraping job"""
        print(f"\n--- Starting WTI crude oil futures scraping job at {datetime.now()} ---")
        
        wti_data = self.scrape_wti()
        if wti_data:
            self.save_to_database(wti_data)
            print(f"ğŸ¯ WTI: ${wti_data['price']} at {wti_data['timestamp']}")
        else:
            print("âŒ Failed to scrape WTI data")
    
    def run_gasoline_stocks_job(self):
        """Run Gasoline Stocks Change scraping job"""
        print(f"\n--- Starting Gasoline Stocks Change scraping job at {datetime.now()} ---")
        
        stocks_data = self.scrape_gasoline_stocks()
        if stocks_data:
            self.save_to_database(stocks_data)
            print(f"ğŸ¯ Gasoline Stocks: {stocks_data['price']}M at {stocks_data['timestamp']}")
        else:
            print("âŒ Failed to scrape Gasoline Stocks data")
    
    def run_refinery_runs_job(self):
        """Run Refinery Crude Runs scraping job"""
        print(f"\n--- Starting Refinery Crude Runs scraping job at {datetime.now()} ---")
        
        runs_data = self.scrape_refinery_runs()
        if runs_data:
            self.save_to_database(runs_data)
            print(f"ğŸ¯ Refinery Runs: {runs_data['price']}M at {runs_data['timestamp']}")
        else:
            print("âŒ Failed to scrape Refinery Runs data")
    
    def run_daily_backup(self):
        """Run daily database backup"""
        print(f"\n--- Starting daily database backup at {datetime.now()} ---")
        
        try:
            # Import and run backup script
            from backup_database import main as backup_main
            backup_main()
            print("âœ… Daily backup completed successfully")
        except Exception as e:
            print(f"âŒ Daily backup failed: {e}")
    
    def run_all_sources_once(self):
        """Run all data sources once immediately"""
        print(f"\n--- Running all sources once at {datetime.now()} ---")
        
        try:
            print("ğŸ”„ Running all sources...")
            self.run_gasbuddy_job()
            time.sleep(2)  # Small delay between jobs
            self.run_aaa_job()
            time.sleep(2)  # Small delay between jobs
            self.run_rbob_job()
            time.sleep(2)  # Small delay between jobs
            self.run_wti_job()
            time.sleep(2)  # Small delay between jobs
            self.run_gasoline_stocks_job()
            time.sleep(2)  # Small delay between jobs
            self.run_refinery_runs_job()
            print("âœ… All sources completed successfully!")
        except Exception as e:
            print(f"âŒ Error running all sources: {e}")
    
    def get_latest_prices(self, limit=20):
        """Retrieve the latest gas prices from the database"""
        try:
            database_url = os.getenv('DATABASE_URL', 'postgresql://postgres:QKmnqfjnamSWVXIgeEZZctczGSYOZiKw@switchback.proxy.rlwy.net:51447/railway')
            conn = psycopg2.connect(database_url)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                ORDER BY scraped_at DESC
                LIMIT %s
            ''', (limit,))
            
            results = cursor.fetchall()
            cursor.close()
            conn.close()
            return results
            
        except Exception as e:
            print(f"Error retrieving data: {e}")
            return []
    
    def export_daily_excel(self):
        """Export today's data to Excel with 3 tabs (GasBuddy, AAA, RBOB)"""
        try:
            print("ğŸ“Š Exporting daily data to Excel...")
            
            # Get today's date
            today = datetime.now().date()
            
            # Connect to database
            database_url = os.getenv('DATABASE_URL', 'postgresql://postgres:QKmnqfjnamSWVXIgeEZZctczGSYOZiKw@switchback.proxy.rlwy.net:51447/railway')
            conn = psycopg2.connect(database_url)
            
            # Get data for each source for today
            gasbuddy_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'gasbuddy_fuel_insights'
                AND DATE(scraped_at) = %s
                ORDER BY scraped_at DESC
            ''', (today,)).fetchall()
            
            aaa_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'aaa_gas_prices'
                AND DATE(scraped_at) = %s
                ORDER BY scraped_at DESC
            ''', (today,)).fetchall()
            
            rbob_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'marketwatch_rbob_futures'
                AND DATE(scraped_at) = %s
                ORDER BY scraped_at DESC
            ''', (today,)).fetchall()
            
            wti_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'marketwatch_wti_futures'
                AND DATE(scraped_at) = %s
                ORDER BY scraped_at DESC
            ''', (today,)).fetchall()
            
            gasoline_stocks_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, consensus, surprise, scraped_at
                FROM gas_prices
                WHERE source = 'tradingeconomics_gasoline_stocks'
                AND DATE(scraped_at) = %s
                ORDER BY scraped_at DESC
            ''', (today,)).fetchall()
            
            refinery_runs_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'tradingeconomics_refinery_runs'
                AND DATE(scraped_at) = %s
                ORDER BY scraped_at DESC
            ''', (today,)).fetchall()
            
            conn.close()
            
            # Create Excel file with 6 tabs
            filename = f"gas_prices_daily_{today.strftime('%Y%m%d')}.xlsx"
            
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # GasBuddy tab
                if gasbuddy_data:
                    gasbuddy_df = pd.DataFrame(gasbuddy_data, 
                                             columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    gasbuddy_df.to_excel(writer, sheet_name='GasBuddy', index=False)
                    print(f"   âœ… GasBuddy: {len(gasbuddy_data)} records")
                else:
                    # Create empty DataFrame with headers
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='GasBuddy', index=False)
                    print("   âš ï¸ GasBuddy: No data for today")
                
                # AAA tab
                if aaa_data:
                    aaa_df = pd.DataFrame(aaa_data, 
                                        columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    aaa_df.to_excel(writer, sheet_name='AAA', index=False)
                    print(f"   âœ… AAA: {len(aaa_data)} record")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='AAA', index=False)
                    print("   âš ï¸ AAA: No data for today")
                
                # RBOB tab
                if rbob_data:
                    rbob_df = pd.DataFrame(rbob_data, 
                                         columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    rbob_df.to_excel(writer, sheet_name='RBOB', index=False)
                    print(f"   âœ… RBOB: {len(rbob_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='RBOB', index=False)
                    print("   âš ï¸ RBOB: No data for today")
                
                # WTI tab
                if wti_data:
                    wti_df = pd.DataFrame(wti_data, 
                                        columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    wti_df.to_excel(writer, sheet_name='WTI', index=False)
                    print(f"   âœ… WTI: {len(wti_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='WTI', index=False)
                    print("   âš ï¸ WTI: No data for today")
                
                # Gasoline Stocks tab
                if gasoline_stocks_data:
                    stocks_df = pd.DataFrame(gasoline_stocks_data, 
                                           columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'consensus', 'surprise', 'scraped_at'])
                    stocks_df.to_excel(writer, sheet_name='Gasoline_Stocks', index=False)
                    print(f"   âœ… Gasoline Stocks: {len(gasoline_stocks_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'consensus', 'surprise', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='Gasoline_Stocks', index=False)
                    print("   âš ï¸ Gasoline Stocks: No data for today")
                
                # Refinery Runs tab
                if refinery_runs_data:
                    runs_df = pd.DataFrame(refinery_runs_data, 
                                         columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    runs_df.to_excel(writer, sheet_name='Refinery_Runs', index=False)
                    print(f"   âœ… Refinery Runs: {len(refinery_runs_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='Refinery_Runs', index=False)
                    print("   âš ï¸ Refinery Runs: No data for today")
            
            print(f"âœ… Daily Excel export completed: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ Error exporting daily Excel: {e}")
            return None
    
    def check_and_export_monthly(self):
        """Check if it's the 1st of the month and export monthly Excel if so"""
        now = datetime.now()
        if now.day == 1:
            print("ğŸ“… First day of month detected - starting monthly Excel export...")
            self.export_monthly_excel()
        else:
            print(f"ğŸ“… Not first day of month (current day: {now.day}) - skipping monthly export")
    
    def export_monthly_excel(self):
        """Export current month's data to Excel with 3 tabs"""
        try:
            print("ğŸ“Š Exporting monthly data to Excel...")
            
            # Get current month
            now = datetime.now()
            current_month = now.replace(day=1).date()
            
            # Connect to database
            database_url = os.getenv('DATABASE_URL', 'postgresql://postgres:QKmnqfjnamSWVXIgeEZZctczGSYOZiKw@switchback.proxy.rlwy.net:51447/railway')
            conn = psycopg2.connect(database_url)
            
            # Get data for each source for current month
            gasbuddy_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'gasbuddy_fuel_insights'
                AND DATE(scraped_at) >= %s
                ORDER BY scraped_at DESC
            ''', (current_month,)).fetchall()
            
            aaa_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'aaa_gas_prices'
                AND DATE(scraped_at) >= %s
                ORDER BY scraped_at DESC
            ''', (current_month,)).fetchall()
            
            rbob_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'marketwatch_rbob_futures'
                AND DATE(scraped_at) >= %s
                ORDER BY scraped_at DESC
            ''', (current_month,)).fetchall()
            
            wti_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'marketwatch_wti_futures'
                AND DATE(scraped_at) >= %s
                ORDER BY scraped_at DESC
            ''', (current_month,)).fetchall()
            
            gasoline_stocks_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, consensus, surprise, scraped_at
                FROM gas_prices
                WHERE source = 'tradingeconomics_gasoline_stocks'
                AND DATE(scraped_at) >= %s
                ORDER BY scraped_at DESC
            ''', (current_month,)).fetchall()
            
            refinery_runs_data = conn.execute('''
                SELECT price, timestamp, region, source, fuel_type, scraped_at
                FROM gas_prices
                WHERE source = 'tradingeconomics_refinery_runs'
                AND DATE(scraped_at) >= %s
                ORDER BY scraped_at DESC
            ''', (current_month,)).fetchall()
            
            conn.close()
            
            # Create Excel file with 6 tabs
            filename = f"gas_prices_monthly_{now.strftime('%Y%m')}.xlsx"
            
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                # GasBuddy tab
                if gasbuddy_data:
                    gasbuddy_df = pd.DataFrame(gasbuddy_data, 
                                             columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    gasbuddy_df.to_excel(writer, sheet_name='GasBuddy', index=False)
                    print(f"   âœ… GasBuddy: {len(gasbuddy_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='GasBuddy', index=False)
                    print("   âš ï¸ GasBuddy: No data for this month")
                
                # AAA tab
                if aaa_data:
                    aaa_df = pd.DataFrame(aaa_data, 
                                        columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    aaa_df.to_excel(writer, sheet_name='AAA', index=False)
                    print(f"   âœ… AAA: {len(aaa_data)} record")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='AAA', index=False)
                    print("   âš ï¸ AAA: No data for this month")
                
                # RBOB tab
                if rbob_data:
                    rbob_df = pd.DataFrame(rbob_data, 
                                         columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    rbob_df.to_excel(writer, sheet_name='RBOB', index=False)
                    print(f"   âœ… RBOB: {len(rbob_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='RBOB', index=False)
                    print("   âš ï¸ RBOB: No data for this month")
                
                # WTI tab
                if wti_data:
                    wti_df = pd.DataFrame(wti_data, 
                                        columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    wti_df.to_excel(writer, sheet_name='WTI', index=False)
                    print(f"   âœ… WTI: {len(wti_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='WTI', index=False)
                    print("   âš ï¸ WTI: No data for this month")
                
                # Gasoline Stocks tab
                if gasoline_stocks_data:
                    stocks_df = pd.DataFrame(gasoline_stocks_data, 
                                           columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'consensus', 'surprise', 'scraped_at'])
                    stocks_df.to_excel(writer, sheet_name='Gasoline_Stocks', index=False)
                    print(f"   âœ… Gasoline Stocks: {len(gasoline_stocks_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'consensus', 'surprise', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='Gasoline_Stocks', index=False)
                    print("   âš ï¸ Gasoline Stocks: No data for this month")
                
                # Refinery Runs tab
                if refinery_runs_data:
                    runs_df = pd.DataFrame(refinery_runs_data, 
                                         columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    runs_df.to_excel(writer, sheet_name='Refinery_Runs', index=False)
                    print(f"   âœ… Refinery Runs: {len(refinery_runs_data)} records")
                else:
                    empty_df = pd.DataFrame(columns=['price', 'timestamp', 'region', 'source', 'fuel_type', 'scraped_at'])
                    empty_df.to_excel(writer, sheet_name='Refinery_Runs', index=False)
                    print("   âš ï¸ Refinery Runs: No data for this month")
            
            print(f"âœ… Monthly Excel export completed: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ Error exporting monthly Excel: {e}")
            return None
    
    def run_scheduled(self):
        """Run the scraper on schedule"""
        print("ğŸš— Hexa Source Gas Scraper - Scheduled Mode")
        print("=" * 50)
        print("ğŸ“… Schedule:")
        print("   â€¢ GasBuddy: Every 15 minutes")
        print("   â€¢ AAA: Daily at 12:01 AM Pacific")
        print("   â€¢ RBOB & WTI: Every 2 hours (Mon 1AM EST - Fri 11PM EST)")
        print("   â€¢ EIA Data (Gasoline Stocks & Refinery Runs): Daily at 11 AM EST")
        print("   â€¢ Daily Excel Export: 5 PM EST")
        print("   â€¢ Monthly Excel Export: 1st of month at 5 PM EST")
        print("   â€¢ Daily Database Backup: 6 PM EST")
        print("=" * 50)
        
        # Schedule GasBuddy every 15 minutes
        schedule.every(15).minutes.do(self.run_gasbuddy_job)
        
        # Schedule AAA daily at 12:01 AM Pacific (3:01 AM Eastern)
        schedule.every().day.at("03:01").do(self.run_aaa_job)
        
        # Schedule EIA data daily at 11 AM EST (4 PM UTC)
        # Schedule EIA data scraping (daily at 10:35 AM EST = 3:35 PM UTC)
        schedule.every().day.at("15:35").do(self.run_gasoline_stocks_job)
        schedule.every().day.at("15:35").do(self.run_refinery_runs_job)
        
        # Schedule daily Excel export at 5 PM EST (10 PM UTC)
        schedule.every().day.at("22:00").do(self.export_daily_excel)
        
        # Schedule monthly Excel export on the 1st of each month at 5 PM EST (10 PM UTC)
        # Schedule monthly Excel export on 1st of month at 5 PM EST (10 PM UTC)
        # Check daily at 10 PM UTC, and export if it's the 1st of the month
        schedule.every().day.at("22:00").do(self.check_and_export_monthly)
        
        # Schedule daily database backup at 11 PM UTC (6 PM EST)
        schedule.every().day.at("23:00").do(self.run_daily_backup)
        
        # Schedule RBOB and WTI every 2 hours during market hours
        # Monday 1AM EST = Monday 6AM UTC, Friday 11PM EST = Saturday 4AM UTC
        for hour in range(6, 24, 2):  # 6, 8, 10, 12, 14, 16, 18, 20, 22
            schedule.every().monday.at(f"{hour:02d}:00").do(self.run_rbob_job)
            schedule.every().monday.at(f"{hour:02d}:00").do(self.run_wti_job)
            schedule.every().tuesday.at(f"{hour:02d}:00").do(self.run_rbob_job)
            schedule.every().tuesday.at(f"{hour:02d}:00").do(self.run_wti_job)
            schedule.every().wednesday.at(f"{hour:02d}:00").do(self.run_rbob_job)
            schedule.every().wednesday.at(f"{hour:02d}:00").do(self.run_wti_job)
            schedule.every().thursday.at(f"{hour:02d}:00").do(self.run_rbob_job)
            schedule.every().thursday.at(f"{hour:02d}:00").do(self.run_wti_job)
            schedule.every().friday.at(f"{hour:02d}:00").do(self.run_rbob_job)
            schedule.every().friday.at(f"{hour:02d}:00").do(self.run_wti_job)
        
        # Add early morning and late night for Friday
        schedule.every().friday.at("00:00").do(self.run_rbob_job)
        schedule.every().friday.at("00:00").do(self.run_wti_job)
        schedule.every().friday.at("02:00").do(self.run_rbob_job)
        schedule.every().friday.at("02:00").do(self.run_wti_job)
        schedule.every().friday.at("04:00").do(self.run_rbob_job)
        schedule.every().friday.at("04:00").do(self.run_wti_job)
        
        print("âœ… Scheduler started!")
        print("Press Ctrl+C to stop")
        
        # Run all sources once immediately when scheduler starts
        print("\nğŸš€ Running all sources once immediately...")
        self.run_all_sources_once()
        print("âœ… Initial run completed! Now continuing with scheduled jobs...")
        
        try:
            while True:
                schedule.run_pending()
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Stopping scheduler...")

def main():
    """Main function to run the gas scraper"""
    print("ğŸš— Hexa Source Gas Scraper - GasBuddy + AAA + RBOB + WTI + EIA Data")
    print("=" * 50)
    
    # Create scraper instance
    scraper = GasScraper(headless=True)
    
    try:
        print("\nğŸš— Gas Scraper Options:")
        print("1. Run GasBuddy once immediately")
        print("2. Run AAA once immediately")
        print("3. Run RBOB once immediately")
        print("4. Run WTI once immediately")
        print("5. Run Gasoline Stocks once immediately")
        print("6. Run Refinery Runs once immediately")
        print("7. Run all sources once")
        print("8. Start scheduled mode (GasBuddy every 10 min + AAA daily + RBOB & WTI every 2h + EIA daily)")
        print("9. View latest data")
        print("10. Export daily Excel")
        print("11. Export monthly Excel")
        print("12. Exit")
        
        choice = input("\nEnter your choice (1-12): ").strip()
        
        if choice == "1":
            scraper.run_gasbuddy_job()
        elif choice == "2":
            scraper.run_aaa_job()
        elif choice == "3":
            scraper.run_rbob_job()
        elif choice == "4":
            scraper.run_wti_job()
        elif choice == "5":
            scraper.run_gasoline_stocks_job()
        elif choice == "6":
            scraper.run_refinery_runs_job()
        elif choice == "7":
            print("ğŸ”„ Running all sources...")
            scraper.run_gasbuddy_job()
            time.sleep(2)  # Small delay between jobs
            scraper.run_aaa_job()
            time.sleep(2)  # Small delay between jobs
            scraper.run_rbob_job()
            time.sleep(2)  # Small delay between jobs
            scraper.run_wti_job()
            time.sleep(2)  # Small delay between jobs
            scraper.run_gasoline_stocks_job()
            time.sleep(2)  # Small delay between jobs
            scraper.run_refinery_runs_job()
        elif choice == "8":
            scraper.run_scheduled()
        elif choice == "9":
            latest_data = scraper.get_latest_prices(20)
            if latest_data:
                print("\nğŸ“Š Latest Gas Prices:")
                for price, timestamp, region, source, fuel_type, scraped_at in latest_data:
                    print(f"${price} - {timestamp} ({region}) - {source} - {fuel_type} - {scraped_at}")
            else:
                print("No data found in database")
        elif choice == "10":
            scraper.export_daily_excel()
        elif choice == "11":
            scraper.export_monthly_excel()
        elif choice == "12":
            print("Exiting...")
        else:
            print("Invalid choice. Exiting...")
            
    except KeyboardInterrupt:
        print("\nInterrupted by user")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")

if __name__ == "__main__":
    main()
